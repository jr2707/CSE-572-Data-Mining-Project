{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing and Data Preparation"
      ],
      "metadata": {
        "id": "4Df3AhNFQ5cB"
      },
      "id": "4Df3AhNFQ5cB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe788f1-b8f6-456b-aa88-83d3af452176",
      "metadata": {
        "id": "dfe788f1-b8f6-456b-aa88-83d3af452176",
        "outputId": "cf728a91-1e16-46a0-f908-4b6d11862e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   day_of_week  hour\n",
            "0          5.0   5.0\n",
            "1          0.0  20.0\n",
            "2          6.0  19.0\n",
            "3          0.0  16.0\n",
            "4          2.0  21.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_excel('merged_post_data.xlsx')  # Update this with the correct path if necessary\n",
        "\n",
        "# Convert 'Created At' to datetime format, forcing UTC to handle mixed time zones\n",
        "data['Created At'] = pd.to_datetime(data['Created At'], errors='coerce', utc=True)\n",
        "\n",
        "# Extract day of the week and hour from 'Created At'\n",
        "data['day_of_week'] = data['Created At'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
        "data['hour'] = data['Created At'].dt.hour              # Hour of the day\n",
        "\n",
        "# Drop the original 'Created At' column if it’s no longer needed\n",
        "data = data.drop(columns=['Created At'])\n",
        "\n",
        "# Display the first few rows to verify the new columns\n",
        "print(data[['day_of_week', 'hour']].head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c709e76-8ae6-4e10-96e4-20a4688e4e47",
      "metadata": {
        "id": "3c709e76-8ae6-4e10-96e4-20a4688e4e47",
        "outputId": "c9d59c82-4a1d-456e-db88-1f47fa7a1547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting textblob\n",
            "  Using cached textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting nltk>=3.8 (from textblob)\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting click (from nltk>=3.8->textblob)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting joblib (from nltk>=3.8->textblob)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk>=3.8->textblob)\n",
            "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tqdm (from nltk>=3.8->textblob)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Using cached textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, regex, joblib, click, nltk, textblob\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.6\n",
            "    Uninstalling tqdm-4.66.6:\n",
            "      Successfully uninstalled tqdm-4.66.6\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.9.11\n",
            "    Uninstalling regex-2024.9.11:\n",
            "      Successfully uninstalled regex-2024.9.11\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: textblob\n",
            "    Found existing installation: textblob 0.18.0.post0\n",
            "    Uninstalling textblob-0.18.0.post0:\n",
            "      Successfully uninstalled textblob-0.18.0.post0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchattacks 3.5.1 requires requests~=2.25.1, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-8.1.7 joblib-1.4.2 nltk-3.9.1 regex-2024.11.6 textblob-0.18.0.post0 tqdm-4.67.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eeec99e-5db3-4c96-be40-c33fd9b2ec37",
      "metadata": {
        "id": "9eeec99e-5db3-4c96-be40-c33fd9b2ec37",
        "outputId": "13808849-ddc6-414b-cefd-127b3cd436fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/bin/python3.12\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f0adb25-7f36-488d-a0eb-b0337de583db",
      "metadata": {
        "id": "6f0adb25-7f36-488d-a0eb-b0337de583db",
        "outputId": "a561f8fa-26ec-4eb0-a38f-ef0b6261cb58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: textblob in ./.local/lib/python3.12/site-packages (0.18.0.post0)\n",
            "Requirement already satisfied: nltk>=3.8 in ./.local/lib/python3.12/site-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in ./.local/lib/python3.12/site-packages (from nltk>=3.8->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages (from nltk>=3.8->textblob) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!{sys.executable} -m pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1da3db-d267-4472-9ae4-4d2f6fa094a1",
      "metadata": {
        "id": "be1da3db-d267-4472-9ae4-4d2f6fa094a1",
        "outputId": "aeacfff9-fb8d-4207-ab4d-7eab75d8c71b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/jravi9/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/jravi9/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt', download_dir='/home/jravi9/nltk_data')\n",
        "nltk.download('averaged_perceptron_tagger', download_dir='/home/jravi9/nltk_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482f93c2-6320-4a2b-9a99-df0412dcba78",
      "metadata": {
        "id": "482f93c2-6320-4a2b-9a99-df0412dcba78",
        "outputId": "b8c0943b-83d4-418b-e225-2a1489f36aec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/jravi9/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /home/jravi9/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/jravi9/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sentiment_score  keyword_count  hashtag_count\n",
            "0            0.000             19              0\n",
            "1            0.025             46              0\n",
            "2            0.340             28              1\n",
            "3            0.000             22              0\n",
            "4            0.000             19              2\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.data.path.append('/home/jravi9/nltk_data')\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Sentiment analysis - Calculate sentiment score for each post\n",
        "data['sentiment_score'] = data['Text'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
        "\n",
        "# Keyword count - Count the number of words in each post\n",
        "data['keyword_count'] = data['Text'].apply(lambda x: len(TextBlob(str(x)).words))\n",
        "\n",
        "# Hashtag count - Count the number of hashtags in each post (assumes hashtags start with '#')\n",
        "data['hashtag_count'] = data['Text'].apply(lambda x: str(x).count('#'))\n",
        "\n",
        "# Drop the original 'Text' column if not needed in the final dataset\n",
        "data = data.drop(columns=['Text'])\n",
        "\n",
        "# Display the first few rows to verify the new text-based features\n",
        "print(data[['sentiment_score', 'keyword_count', 'hashtag_count']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20b8eb1d-b1c8-4250-beb5-a76be55a81fe",
      "metadata": {
        "id": "20b8eb1d-b1c8-4250-beb5-a76be55a81fe",
        "outputId": "43a51a8f-997f-4327-92be-bddb610aef47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature set shape: (201229, 8)\n",
            "Target set shape: (201229, 2)\n",
            "Training set shape (X_train, y_train): (160983, 8) (160983, 2)\n",
            "Testing set shape (X_test, y_test): (40246, 8) (40246, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define feature columns and target columns\n",
        "feature_columns = [\n",
        "    'followers_count', 'follows_count', 'Total Posts', 'day_of_week', 'hour',\n",
        "    'sentiment_score', 'keyword_count', 'hashtag_count'\n",
        "]\n",
        "target_columns = ['Likes', 'Reposts']\n",
        "\n",
        "# Create feature set (X) and target set (y)\n",
        "X = data[feature_columns]\n",
        "y = data[target_columns]\n",
        "\n",
        "# Split the data into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display shapes to verify\n",
        "print(\"Feature set shape:\", X.shape)\n",
        "print(\"Target set shape:\", y.shape)\n",
        "print(\"Training set shape (X_train, y_train):\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape (X_test, y_test):\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree, Random Forest and Support Vector Models"
      ],
      "metadata": {
        "id": "qsn4BL-4RCNZ"
      },
      "id": "qsn4BL-4RCNZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e4731da-c812-4b46-8326-eef472a8a632",
      "metadata": {
        "id": "0e4731da-c812-4b46-8326-eef472a8a632",
        "outputId": "bc01d0c9-ef05-47e9-9580-336ff7a1bd56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Results for 'Likes' ---\n",
            "Decision Tree Results for 'Likes':\n",
            "  MAE: 9.218481816901534\n",
            "  RMSE: 18.29544796279807\n",
            "  R2 Score: -0.11198167579830454\n",
            "\n",
            "Random Forest Results for 'Likes':\n",
            "  MAE: 8.874137158058472\n",
            "  RMSE: 13.69072069032333\n",
            "  R2 Score: 0.3773210906540202\n",
            "\n",
            "SVM Results for 'Likes':\n",
            "  MAE: 9.837814670645114\n",
            "  RMSE: 18.782381502945185\n",
            "  R2 Score: -0.17196016580454154\n",
            "\n",
            "\n",
            "--- Results for 'Reposts' ---\n",
            "Decision Tree Results for 'Reposts':\n",
            "  MAE: 7.024520150955075\n",
            "  RMSE: 16.359421215359077\n",
            "  R2 Score: -0.2798868501823504\n",
            "\n",
            "Random Forest Results for 'Reposts':\n",
            "  MAE: 6.825009232613107\n",
            "  RMSE: 12.089058458472294\n",
            "  R2 Score: 0.3010909513075486\n",
            "\n",
            "SVM Results for 'Reposts':\n",
            "  MAE: 6.217932773179131\n",
            "  RMSE: 15.553235236470051\n",
            "  R2 Score: -0.15685036797467755\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Impute missing values in X_train and X_test\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'R2 Score': r2}\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
        "    'Random Forest': RandomForestRegressor(random_state=42),\n",
        "    'SVM': SVR()\n",
        "}\n",
        "\n",
        "# Define target variables to evaluate\n",
        "targets = ['Likes', 'Reposts']\n",
        "\n",
        "# Train and evaluate each model for each target variable\n",
        "for target in targets:\n",
        "    print(f\"\\n--- Results for '{target}' ---\")\n",
        "    results = {}\n",
        "    for model_name, model in models.items():\n",
        "        # Train the model on the current target using imputed data\n",
        "        model.fit(X_train_imputed, y_train[target])\n",
        "\n",
        "        # Make predictions on the test set\n",
        "        y_pred = model.predict(X_test_imputed)\n",
        "\n",
        "        # Evaluate the model\n",
        "        results[model_name] = evaluate_model(y_test[target], y_pred)\n",
        "\n",
        "    # Display results for each model\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"{model_name} Results for '{target}':\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"  {metric}: {value}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimized Random Forest Model"
      ],
      "metadata": {
        "id": "DWmMv0_yRIXn"
      },
      "id": "DWmMv0_yRIXn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46f720ca-b835-4e6e-82f6-4c11180c7c4d",
      "metadata": {
        "id": "46f720ca-b835-4e6e-82f6-4c11180c7c4d",
        "outputId": "02257827-1877-4947-e315-4ce295e85bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Random Forest for 'Likes'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "15 fits failed out of a total of 60.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1052: UserWarning: One or more of the test scores are non-finite: [-214.05301432           nan -209.66047579           nan -209.21496593\n",
            " -211.33645926 -206.00545443 -252.27008781 -209.04172605 -218.16188408\n",
            " -218.60061499 -202.68989664 -222.86078566 -221.13777667 -252.44801509\n",
            "           nan           nan           nan -204.99178084 -212.88393303]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters found for 'Likes':  {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 40}\n",
            "Optimized Random Forest Results for 'Likes':\n",
            "  MAE: 9.418351021872175\n",
            "  RMSE: 13.790862225951022\n",
            "  R2 Score: 0.3681785368189914\n",
            "\n",
            "Training Random Forest for 'Reposts'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "15 fits failed out of a total of 60.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/packages/envs/pytorch-gpu-2.3.1-cuda-12.1/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1052: UserWarning: One or more of the test scores are non-finite: [-162.2148191            nan -159.93784323           nan -158.96510677\n",
            " -159.33266648 -157.57142426 -182.54935472 -159.75307624 -164.01041416\n",
            " -163.58311419 -155.30152873 -166.40827998 -165.67162924 -182.80987164\n",
            "           nan           nan           nan -157.62794461 -160.2436296 ]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters found for 'Reposts':  {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 40}\n",
            "Optimized Random Forest Results for 'Reposts':\n",
            "  MAE: 7.184896001069873\n",
            "  RMSE: 12.12936002515979\n",
            "  R2 Score: 0.2964232461378222\n",
            "\n",
            "Final Evaluation Results:\n",
            "Likes Results:  {'MAE': 9.418351021872175, 'RMSE': 13.790862225951022, 'R2 Score': 0.3681785368189914}\n",
            "Reposts Results:  {'MAE': 7.184896001069873, 'RMSE': 12.12936002515979, 'R2 Score': 0.2964232461378222}\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Example: Load your dataset (replace this with your actual dataset)\n",
        "# Ensure `X_train_imputed`, `X_test_imputed`, `y_train`, and `y_test` are defined\n",
        "# Example placeholders:\n",
        "# X_train_imputed, X_test_imputed: Preprocessed feature matrices\n",
        "# y_train, y_test: DataFrames containing target variables ('Likes' and 'Reposts')\n",
        "# Replace this with actual data loading and preprocessing logic\n",
        "# X_train_imputed, X_test_imputed, y_train, y_test = ...\n",
        "\n",
        "# Define the parameter grid for RandomizedSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 300, 400],\n",
        "    'max_depth': [None, 10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest Regressor\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Define a function to train and evaluate for a specific target variable\n",
        "def train_and_evaluate_target(target_name):\n",
        "    print(f\"\\nTraining Random Forest for '{target_name}'\")\n",
        "\n",
        "    # Initialize RandomizedSearchCV\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=rf,\n",
        "        param_distributions=param_grid,\n",
        "        n_iter=20,  # Number of different combinations to try\n",
        "        scoring='neg_mean_squared_error',  # Scoring based on RMSE\n",
        "        cv=3,  # 3-fold cross-validation\n",
        "        random_state=42,\n",
        "        n_jobs=-1  # Use all available CPU cores\n",
        "    )\n",
        "\n",
        "    # Fit RandomizedSearchCV on the training data for the target variable\n",
        "    random_search.fit(X_train_imputed, y_train[target_name])\n",
        "\n",
        "    # Best parameters from RandomizedSearchCV\n",
        "    best_params = random_search.best_params_\n",
        "    print(f\"Best parameters found for '{target_name}': \", best_params)\n",
        "\n",
        "    # Train the optimized Random Forest model with the best parameters\n",
        "    optimized_rf = RandomForestRegressor(**best_params, random_state=42)\n",
        "    optimized_rf.fit(X_train_imputed, y_train[target_name])\n",
        "\n",
        "    # Make predictions with the optimized model\n",
        "    y_pred_optimized = optimized_rf.predict(X_test_imputed)\n",
        "\n",
        "    # Evaluate the optimized model\n",
        "    optimized_results = {\n",
        "        'MAE': mean_absolute_error(y_test[target_name], y_pred_optimized),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test[target_name], y_pred_optimized)),\n",
        "        'R2 Score': r2_score(y_test[target_name], y_pred_optimized)\n",
        "    }\n",
        "\n",
        "    print(f\"Optimized Random Forest Results for '{target_name}':\")\n",
        "    for metric, value in optimized_results.items():\n",
        "        print(f\"  {metric}: {value}\")\n",
        "\n",
        "    return optimized_results, optimized_rf\n",
        "\n",
        "# Train and evaluate for 'Likes'\n",
        "likes_results, likes_model = train_and_evaluate_target('Likes')\n",
        "\n",
        "# Train and evaluate for 'Reposts'\n",
        "reposts_results, reposts_model = train_and_evaluate_target('Reposts')\n",
        "\n",
        "# Final results\n",
        "print(\"\\nFinal Evaluation Results:\")\n",
        "print(\"Likes Results: \", likes_results)\n",
        "print(\"Reposts Results: \", reposts_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e32c6c35-5738-41ad-a5b3-bf76099d1b65",
      "metadata": {
        "id": "e32c6c35-5738-41ad-a5b3-bf76099d1b65",
        "outputId": "6bcec6c6-e16e-4eca-86f8-19ab76fc3dfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: xgboost in ./.local/lib/python3.11/site-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /packages/envs/pytorch-gpu-2.0.1/lib/python3.11/site-packages (from xgboost) (1.26.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in ./.local/lib/python3.11/site-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /packages/envs/pytorch-gpu-2.0.1/lib/python3.11/site-packages (from xgboost) (1.11.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost Model"
      ],
      "metadata": {
        "id": "3-lE76W2ROvj"
      },
      "id": "3-lE76W2ROvj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cabd6f25-e1a9-4e38-a69c-794f1deeed74",
      "metadata": {
        "id": "cabd6f25-e1a9-4e38-a69c-794f1deeed74",
        "outputId": "36243996-8fc2-4494-9920-1dbb8c9e23af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training XGBoost Model for 'Likes'\n",
            "XGBoost Results for 'Likes':\n",
            "  MAE: 10.493507848696245\n",
            "  RMSE: 14.838222630026472\n",
            "  R2 Score: 0.2685657739639282\n",
            "\n",
            "Training XGBoost Model for 'Reposts'\n",
            "XGBoost Results for 'Reposts':\n",
            "  MAE: 7.800660039702633\n",
            "  RMSE: 12.875401376225458\n",
            "  R2 Score: 0.2072116732597351\n",
            "\n",
            "Final Evaluation Results:\n",
            "Likes Results:  {'MAE': 10.493507848696245, 'RMSE': 14.838222630026472, 'R2 Score': 0.2685657739639282}\n",
            "Reposts Results:  {'MAE': 7.800660039702633, 'RMSE': 12.875401376225458, 'R2 Score': 0.2072116732597351}\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to train and evaluate an XGBoost model for a specific target variable\n",
        "def train_and_evaluate_xgb(target_name):\n",
        "    print(f\"\\nTraining XGBoost Model for '{target_name}'\")\n",
        "\n",
        "    # Initialize the XGBoost model\n",
        "    xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "    # Train the model on the target variable\n",
        "    xgb_model.fit(X_train_imputed, y_train[target_name])\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_xgb = xgb_model.predict(X_test_imputed)\n",
        "\n",
        "    # Evaluate the XGBoost model\n",
        "    xgb_results = {\n",
        "        'MAE': mean_absolute_error(y_test[target_name], y_pred_xgb),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test[target_name], y_pred_xgb)),\n",
        "        'R2 Score': r2_score(y_test[target_name], y_pred_xgb)\n",
        "    }\n",
        "\n",
        "    print(f\"XGBoost Results for '{target_name}':\")\n",
        "    for metric, value in xgb_results.items():\n",
        "        print(f\"  {metric}: {value}\")\n",
        "\n",
        "    return xgb_results, xgb_model\n",
        "\n",
        "# Train and evaluate the XGBoost model for 'Likes'\n",
        "likes_results, likes_model = train_and_evaluate_xgb('Likes')\n",
        "\n",
        "# Train and evaluate the XGBoost model for 'Reposts'\n",
        "reposts_results, reposts_model = train_and_evaluate_xgb('Reposts')\n",
        "\n",
        "# Display final results\n",
        "print(\"\\nFinal Evaluation Results:\")\n",
        "print(\"Likes Results: \", likes_results)\n",
        "print(\"Reposts Results: \", reposts_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimized XGBoost Model"
      ],
      "metadata": {
        "id": "O8BEnmubRU9c"
      },
      "id": "O8BEnmubRU9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb50bdf-e933-4df2-b86e-3fefab8d6800",
      "metadata": {
        "id": "2eb50bdf-e933-4df2-b86e-3fefab8d6800",
        "outputId": "5aa7890c-0e16-48e2-bb25-64a60f1b8c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training XGBoost Model for 'Likes'\n",
            "Best parameters found for 'Likes':  {'subsample': 0.8, 'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "Optimized XGBoost Results for 'Likes':\n",
            "  MAE: 9.134765558342947\n",
            "  RMSE: 13.749280693573356\n",
            "  R2 Score: 0.3719828724861145\n",
            "\n",
            "Training XGBoost Model for 'Reposts'\n",
            "Best parameters found for 'Reposts':  {'subsample': 0.8, 'n_estimators': 400, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
            "Optimized XGBoost Results for 'Reposts':\n",
            "  MAE: 7.056903942805093\n",
            "  RMSE: 12.139804382120126\n",
            "  R2 Score: 0.29521113634109497\n",
            "\n",
            "Final Evaluation Results:\n",
            "Likes Results:  {'MAE': 9.134765558342947, 'RMSE': 13.749280693573356, 'R2 Score': 0.3719828724861145}\n",
            "Reposts Results:  {'MAE': 7.056903942805093, 'RMSE': 12.139804382120126, 'R2 Score': 0.29521113634109497}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2, 0.3]\n",
        "}\n",
        "\n",
        "# Define a function to train and evaluate an XGBoost model for a specific target variable\n",
        "def train_and_evaluate_xgb(target_name):\n",
        "    print(f\"\\nTraining XGBoost Model for '{target_name}'\")\n",
        "\n",
        "    # Initialize the XGBoost model\n",
        "    xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "    # Initialize RandomizedSearchCV\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=xgb_model,\n",
        "        param_distributions=param_grid,\n",
        "        n_iter=20,  # Number of parameter combinations to try\n",
        "        scoring='neg_mean_squared_error',  # Optimize for RMSE\n",
        "        cv=3,  # 3-fold cross-validation\n",
        "        random_state=42,\n",
        "        n_jobs=-1  # Use all CPU cores\n",
        "    )\n",
        "\n",
        "    # Fit RandomizedSearchCV on the training data for the target variable\n",
        "    random_search.fit(X_train_imputed, y_train[target_name])\n",
        "\n",
        "    # Best parameters from RandomizedSearchCV\n",
        "    best_params = random_search.best_params_\n",
        "    print(f\"Best parameters found for '{target_name}': \", best_params)\n",
        "\n",
        "    # Train the optimized XGBoost model with the best parameters\n",
        "    optimized_xgb = XGBRegressor(**best_params, objective='reg:squarederror', random_state=42)\n",
        "    optimized_xgb.fit(X_train_imputed, y_train[target_name])\n",
        "\n",
        "    # Make predictions with the optimized model\n",
        "    y_pred_optimized_xgb = optimized_xgb.predict(X_test_imputed)\n",
        "\n",
        "    # Evaluate the optimized model\n",
        "    optimized_xgb_results = {\n",
        "        'MAE': mean_absolute_error(y_test[target_name], y_pred_optimized_xgb),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test[target_name], y_pred_optimized_xgb)),\n",
        "        'R2 Score': r2_score(y_test[target_name], y_pred_optimized_xgb)\n",
        "    }\n",
        "\n",
        "    print(f\"Optimized XGBoost Results for '{target_name}':\")\n",
        "    for metric, value in optimized_xgb_results.items():\n",
        "        print(f\"  {metric}: {value}\")\n",
        "\n",
        "    return optimized_xgb_results, optimized_xgb\n",
        "\n",
        "# Train and evaluate the XGBoost model for 'Likes'\n",
        "likes_results, likes_model = train_and_evaluate_xgb('Likes')\n",
        "\n",
        "# Train and evaluate the XGBoost model for 'Reposts'\n",
        "reposts_results, reposts_model = train_and_evaluate_xgb('Reposts')\n",
        "\n",
        "# Display final results\n",
        "print(\"\\nFinal Evaluation Results:\")\n",
        "print(\"Likes Results: \", likes_results)\n",
        "print(\"Reposts Results: \", reposts_results)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}